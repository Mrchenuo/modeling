{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.decomposition import KernelPCA, PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# 1 加载数据\n",
    "train_X_df = pd.read_excel(r\"D:\\GitHub\\modeling\\D\\ans3\\Molecular_Descriptor.xlsx\", engine='openpyxl',\n",
    "                           sheet_name='training')\n",
    "train_Y_df = pd.read_excel(r\"D:\\GitHub\\modeling\\D\\ans3\\ADMET.xlsx\", engine='openpyxl', sheet_name='training')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# 只用第一问的20个特征\n",
    "var = ['MDEC-23', 'minsssN', 'LipoaffinityIndex', 'maxHsOH', 'maxssO', 'C1SP2',\n",
    "                   'minHsOH', 'BCUTc-1l', 'minsOH', 'minHBint5', 'MLFER_A', 'nHBAcc', 'VC-5',\n",
    "                   'MDEO-12', 'ndssC', 'TopoPSA', 'ATSc3', 'SHBint10', 'MDEC-33', 'XLogP']\n",
    "var_top20 = pd.Index(var)\n",
    "# var_top20 = pd.Index(var_top20)\n",
    "# X_train_df = train_X_df[var_top20]\n",
    "X_train_df = train_X_df\n",
    "\n",
    "X = X_train_df.iloc[:, 1:].values  # 去掉第一列\n",
    "Y = train_Y_df.iloc[:, 5].values  # 选择指定label（从1开始）\n",
    "\n",
    "# TODO:找出全零的列，将其剔除"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# 2 降维\n",
    "# scikit_kpca = KernelPCA()\n",
    "#\n",
    "# # 使用KPCA降低数据维度，直接获得投影后的坐标\n",
    "# X = scikit_kpca.fit_transform(X)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "# 3 分割训练数据和测试数据\n",
    "# random_state 设置随机数为33\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=33)\n",
    "\n",
    "# 3 在训练之前，我们需要对数据进行规范化，这样让数据同在同一个量级上，避免因为维度问题造成数据误差：\n",
    "# 采用 Z-Score 规范化数据，保证每个特征维度的数据均值为 0，方差为 1\n",
    "ss = StandardScaler()\n",
    "x_train = ss.fit_transform(x_train)\n",
    "x_test = ss.transform(x_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm准确率:  0.9088607594936708\n"
     ]
    }
   ],
   "source": [
    "# 4 创建 SVM 分类器\n",
    "# model_svm = svm.SVC(kernel='poly',degree=8, gamma='auto')\n",
    "model_svm = svm.SVC()\n",
    "# 用训练集做训练\n",
    "model_svm.fit(x_train, y_train)\n",
    "# 用测试集做预测\n",
    "p_svm = model_svm.predict(x_test)\n",
    "print('svm准确率: ', metrics.accuracy_score(p_svm, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "def modelfit(alg, x_train, y_train, x_test, y_test, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "            metrics='auc', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "\n",
    "    #Fit the algorithm on the data\n",
    "    alg.fit(x_train, y_train,eval_metric='auc')\n",
    "\n",
    "    #Predict training set:\n",
    "    dtrain_predictions = alg.predict(x_test)\n",
    "    dtrain_predprob = alg.predict_proba(x_test)[:,1]\n",
    "\n",
    "    #Print model report:\n",
    "    print(\"\\nModel Report\")\n",
    "    print(\"Accuracy : %.4g\" % metrics.accuracy_score(y_test, dtrain_predictions))\n",
    "    print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(y_test, dtrain_predprob))\n",
    "\n",
    "    # feat_imp = pd.Series(alg.get_booster().get_fscore()).sort_values(ascending=False)[:20]\n",
    "    # feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    # plt.ylabel('Feature Importance Score')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuo_nuaa\\anaconda3\\envs\\diveintoDL\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.9468\n",
      "AUC Score (Train): 0.985990\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb1, x_train, y_train, x_test, y_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "xgb_test = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=7,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.7,\n",
    " colsample_bytree=0.7,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "\n",
    "# param_test1 = {\n",
    "#  'max_depth':range(3,10,2),\n",
    "#  'min_child_weight':range(1,6,2)\n",
    "# }\n",
    "# param_test3 = {\n",
    "#  'gamma':[i/10.0 for i in range(0,5)]\n",
    "# }\n",
    "param_test4 = {\n",
    " 'subsample':[i/10.0 for i in range(6,10)],\n",
    " 'colsample_bytree':[i/10.0 for i in range(6,10)]\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = xgb_test, param_grid = param_test4 , scoring='roc_auc',n_jobs=4, cv=5)\n",
    "# gsearch1.fit(x_train,y_train)\n",
    "# gsearch1.cv_results_, gsearch1.best_params_, gsearch1.best_score_\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuo_nuaa\\anaconda3\\envs\\diveintoDL\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Report\n",
      "Accuracy : 0.9443\n",
      "AUC Score (Train): 0.987169\n"
     ]
    }
   ],
   "source": [
    "xgb2 = XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=1000,\n",
    " max_depth=7,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.7,\n",
    " colsample_bytree=0.7,\n",
    " objective= 'binary:logistic',\n",
    " nthread=4,\n",
    " scale_pos_weight=1,\n",
    " seed=27)\n",
    "modelfit(xgb2, x_train, y_train, x_test, y_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:02:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nuo_nuaa\\anaconda3\\envs\\diveintoDL\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgboost准确率:  0.9493670886075949\n"
     ]
    }
   ],
   "source": [
    "# 5 xgboost\n",
    "# model_xgboost = XGBClassifier(learning_rate=0.01,\n",
    "#                       n_estimators=10,           # 树的个数-10棵树建立xgboost\n",
    "#                       max_depth=4,               # 树的深度\n",
    "#                       min_child_weight = 1,      # 叶子节点最小权重\n",
    "#                       gamma=0.,                  # 惩罚项中叶子结点个数前的参数\n",
    "#                       subsample=1,               # 所有样本建立决策树\n",
    "#                       colsample_btree=1,         # 所有特征建立决策树\n",
    "#                       scale_pos_weight=1,        # 解决样本个数不平衡的问题\n",
    "#                       random_state=27,           # 随机数\n",
    "#                       slient = 0\n",
    "#                       )\n",
    "model_xgboost = XGBClassifier(booster='gbtree', )\n",
    "model_xgboost.fit(x_train, y_train)\n",
    "# 用测试集做预测\n",
    "p_xgboost = model_xgboost.predict(x_test)\n",
    "print('xgboost准确率: ', metrics.accuracy_score(p_xgboost, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "# 测试结果\n",
    "test_X_df = pd.read_excel(r\"D:\\GitHub\\modeling\\D\\ans3\\Molecular_Descriptor.xlsx\", engine='openpyxl',\n",
    "                           sheet_name='test')\n",
    "test_X = test_X_df.iloc[:, 1:].values  # 去掉第一列\n",
    "pred = model_xgboost.predict(test_X)\n",
    "# list转dataframe\n",
    "# col_name = 'CYP3A4'\n",
    "# col_name = 'hERG'\n",
    "# col_name = 'HOB'\n",
    "col_name = 'MN'\n",
    "\n",
    "df = pd.DataFrame(pred, columns=[col_name])\n",
    "# 保存到本地excel\n",
    "df.to_excel(col_name + \".xlsx\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "随机森林准确率:  0.9392405063291139\n"
     ]
    }
   ],
   "source": [
    "# 6 随机森林\n",
    "# model_rf = RandomForestClassifier(n_estimators = 1000, max_depth=None, random_state=0)\n",
    "model_rf = RandomForestClassifier()\n",
    "model_rf.fit(x_train, y_train)\n",
    "# 用测试集做预测\n",
    "p_rf = model_rf.predict(x_test)\n",
    "print('随机森林准确率: ', metrics.accuracy_score(p_rf, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}